{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Churn Prediction using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset ... \n",
      "This data set contains 3333 data and 17 features\n",
      "\n",
      "Imputing missing values for the following features ...\n",
      "Int'l Plan\n",
      "VMail Plan\n",
      "Day Charge\n",
      "Eve Mins\n",
      "Eve Calls\n",
      "Night Charge\n",
      "Intl Calls\n",
      "Intl Charge\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sukilau/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/sukilau/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/sukilau/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/sukilau/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training random forest classifier and finding the best parameters ...\n",
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:   46.8s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set :\n",
      "{'max_depth': 10, 'n_estimators': 500}\n",
      "\n",
      "Best score: 0.902\n",
      "\n",
      "Grid scores :\n",
      "0.899 (+/-0.073) for {'max_depth': 10, 'n_estimators': 10}\n",
      "0.902 (+/-0.087) for {'max_depth': 10, 'n_estimators': 100}\n",
      "0.902 (+/-0.086) for {'max_depth': 10, 'n_estimators': 500}\n",
      "0.901 (+/-0.092) for {'max_depth': 10, 'n_estimators': 1000}\n",
      "0.891 (+/-0.067) for {'max_depth': None, 'n_estimators': 10}\n",
      "0.900 (+/-0.087) for {'max_depth': None, 'n_estimators': 100}\n",
      "0.897 (+/-0.084) for {'max_depth': None, 'n_estimators': 500}\n",
      "0.896 (+/-0.089) for {'max_depth': None, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# load data\n",
    "print(\"Loading dataset ... \")\n",
    "df = pd.read_csv(\"churn.csv\", header=0, delimiter=\",\")\n",
    "\n",
    "\n",
    "# convert strings to boolean for the labels\n",
    "y = df[\"Churn?\"]\n",
    "y = np.where(df[\"Churn?\"] == \"True.\",1,0)\n",
    "\n",
    "\n",
    "# drop irrelevant columns\n",
    "X = df.drop([\"Unnamed: 0\",\"State\",\"Area Code\",\"Phone\",\"Churn?\"],axis=1)\n",
    "features = X.columns\n",
    "print(\"This data set contains %d data and %d features\" % X.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "# impute missing values\n",
    "print(\"Imputing missing values for the following features ...\")\n",
    "X = X.replace('?', np.NaN)\n",
    "for i in range(1, len(features)):\n",
    "    if X[features[i]].isnull().values.any():\n",
    "        print(features[i])\n",
    "print()\n",
    "X[\"Int'l Plan\"] = X[\"Int'l Plan\"].fillna(X[\"Int'l Plan\"].mode()[0])\n",
    "X[\"VMail Plan\"] = X[\"VMail Plan\"].fillna(X[\"VMail Plan\"].mode()[0])\n",
    "X[\"Day Charge\"] = X[\"Day Charge\"].fillna(X[\"Day Charge\"].median())\n",
    "X[\"Day Charge\"] = X[\"Day Charge\"].fillna(X[\"Day Charge\"].median())\n",
    "X[\"Eve Mins\"] = X[\"Eve Mins\"].fillna(X[\"Eve Mins\"].median())\n",
    "X[\"Eve Calls\"] = X[\"Eve Calls\"].fillna(X[\"Eve Calls\"].median())\n",
    "X[\"Night Charge\"] = X[\"Night Charge\"].fillna(X[\"Night Charge\"].median())\n",
    "X[\"Intl Calls\"] = X[\"Intl Calls\"].fillna(X[\"Intl Calls\"].median())\n",
    "X[\"Intl Charge\"] = X[\"Intl Charge\"].fillna(X[\"Intl Charge\"].median())\n",
    "\n",
    "\n",
    "# convert strings to boolean\n",
    "X[\"Int'l Plan\"][X[\"Int'l Plan\"] == \"no\"] = 0\n",
    "X[\"Int'l Plan\"][X[\"Int'l Plan\"] == \"yes\"] = 1\n",
    "X[\"VMail Plan\"][X[\"VMail Plan\"] == \"no\"] = 0\n",
    "X[\"VMail Plan\"][X[\"VMail Plan\"] == \"yes\"] = 1\n",
    "\n",
    "\n",
    "# print csv to store the cleaned dataset for future use\n",
    "clean_df = X.copy()\n",
    "clean_df[\"churn\"] = y\n",
    "clean_df.to_csv(\"churn_clean.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "\n",
    "# standandize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# Tuning hyper-parameter for random forest classifier using grid search with roc_auc_score on 10-fold cross validation\n",
    "print(\"Training random forest classifier and finding the best parameters ...\")\n",
    "parameters = {\"n_estimators\": [10, 100, 500, 1000],\n",
    "#               \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"max_depth\": [10, None],\n",
    "#               \"min_samples_split\": sp_randint(1, 11),\n",
    "#               \"min_samples_leaf\": sp_randint(1, 11),\n",
    "#               \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "#               \"min_impurity_split\": [1e-07],\n",
    "#               \"bootstrap\": [True, False],            \n",
    "              }\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), parameters, cv=10, scoring=\"roc_auc\", n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X,y)\n",
    "print()\n",
    "print(\"Best parameters set :\")\n",
    "print(grid_search.best_params_)\n",
    "print()\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print()\n",
    "print(\"Grid scores :\")\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
